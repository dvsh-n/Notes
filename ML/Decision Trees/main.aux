\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Mathematical Formulation}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Entropy and Information Gain}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Gini Index}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Structure of Decision Trees}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}How Decision Trees Work}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Splitting Criteria}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Algorithm for Building a Decision Tree}{3}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Decision Tree Algorithm}}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Numerical Example}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Step 1: Calculate Entropy of the Entire Dataset}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Step 2: Calculate Information Gain for Each Attribute}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Step 3: Repeat the Process for Each Subset}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Resulting Decision Tree}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{6}{}\protected@file@percent }
\gdef \@abspage@last{6}
